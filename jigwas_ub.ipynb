{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\\\data\\\\train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target                                       comment_text  \\\n",
       "0  59848  0.000000  This is so cool. It's like, 'would you want yo...   \n",
       "1  59849  0.000000  Thank you!! This would make my life a lot less...   \n",
       "2  59852  0.000000  This is such an urgent design problem; kudos t...   \n",
       "3  59855  0.000000  Is this something I'll be able to install on m...   \n",
       "4  59856  0.893617               haha you guys are a bunch of losers.   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "             ...             article_id    rating  funny  wow  sad  likes  \\\n",
       "0            ...                   2006  rejected      0    0    0      0   \n",
       "1            ...                   2006  rejected      0    0    0      0   \n",
       "2            ...                   2006  rejected      0    0    0      0   \n",
       "3            ...                   2006  rejected      0    0    0      0   \n",
       "4            ...                   2006  rejected      0    0    0      1   \n",
       "\n",
       "   disagree  sexual_explicit  identity_annotator_count  \\\n",
       "0         0              0.0                         0   \n",
       "1         0              0.0                         0   \n",
       "2         0              0.0                         0   \n",
       "3         0              0.0                         0   \n",
       "4         0              0.0                         4   \n",
       "\n",
       "   toxicity_annotator_count  \n",
       "0                         4  \n",
       "1                         4  \n",
       "2                         4  \n",
       "3                         4  \n",
       "4                        47  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.columns[8:-13]\n",
    "target_columns = ['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NANs:  1399744\n",
      "data rows:  1804874\n",
      "non-NANs:  405130\n"
     ]
    }
   ],
   "source": [
    "nan_count = df[groups].loc[:, 'asian'].isna().sum()\n",
    "length = df.shape[0]\n",
    "print('NANs: ', nan_count)\n",
    "print('data rows: ', length)\n",
    "print('non-NANs: ', length - nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = None\n",
    "for group in groups:\n",
    "    if s is None:\n",
    "        s = df[groups].loc[:, group].isna().sum()\n",
    "    else:\n",
    "        assert s == df[groups].loc[:, group].isna().sum(), 'Amount of NANs doesn\\'t match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net training size:  1399744\n",
      "Boosting training size:  405130\n"
     ]
    }
   ],
   "source": [
    "nan_mask = df[groups].iloc[:, 0].isna()\n",
    "\n",
    "df_train_net = df[nan_mask]\n",
    "df_train_boost = df[~nan_mask]\n",
    "\n",
    "print('Net training size: ', df_train_net.shape[0])\n",
    "print('Boosting training size: ', df_train_boost.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_net = df_train_net.drop(groups, axis='columns')\n",
    "target_net = df_train_net[target_columns]\n",
    "df_train_net = df_train_net.drop(target_net, axis='columns')\n",
    "df_train_net = df_train_net[['id', 'comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat((df_train_net, target_net), axis='columns')\n",
    "train_df.to_csv('.\\\\data\\\\train_set.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>target</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59859</td>\n",
       "      <td>ur a sh*tty comment.</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59861</td>\n",
       "      <td>hahahahahahahahhha suck it.</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>59863</td>\n",
       "      <td>FFFFUUUUUUUUUUUUUUU</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>239575</td>\n",
       "      <td>The ranchers seem motivated by mostly by greed...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>239576</td>\n",
       "      <td>It was a great show. Not a combo I'd of expect...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>239578</td>\n",
       "      <td>Wow, that sounds great.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       comment_text    target  \\\n",
       "0    59848  This is so cool. It's like, 'would you want yo...  0.000000   \n",
       "1    59849  Thank you!! This would make my life a lot less...  0.000000   \n",
       "2    59852  This is such an urgent design problem; kudos t...  0.000000   \n",
       "3    59855  Is this something I'll be able to install on m...  0.000000   \n",
       "5    59859                               ur a sh*tty comment.  0.666667   \n",
       "6    59861                        hahahahahahahahhha suck it.  0.457627   \n",
       "7    59863                                FFFFUUUUUUUUUUUUUUU  0.000000   \n",
       "8   239575  The ranchers seem motivated by mostly by greed...  0.000000   \n",
       "9   239576  It was a great show. Not a combo I'd of expect...  0.000000   \n",
       "10  239578                            Wow, that sounds great.  0.000000   \n",
       "\n",
       "    severe_toxicity   obscene  identity_attack    insult  threat  \n",
       "0          0.000000  0.000000              0.0  0.000000     0.0  \n",
       "1          0.000000  0.000000              0.0  0.000000     0.0  \n",
       "2          0.000000  0.000000              0.0  0.000000     0.0  \n",
       "3          0.000000  0.000000              0.0  0.000000     0.0  \n",
       "5          0.047619  0.638095              0.0  0.333333     0.0  \n",
       "6          0.050847  0.305085              0.0  0.254237     0.0  \n",
       "7          0.000000  0.000000              0.0  0.000000     0.0  \n",
       "8          0.000000  0.000000              0.0  0.000000     0.0  \n",
       "9          0.000000  0.000000              0.0  0.000000     0.0  \n",
       "10         0.000000  0.000000              0.0  0.000000     0.0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_path = \"..\\\\Dasha\\\\embeddings\\\\crawl-300d-2M.vec\"\n",
    "emb_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from ..\\Dasha\\embeddings\\crawl-300d-2M.vec...\n",
      "Done.\n",
      "Loading text...\n",
      "Index(['id', 'comment_text', 'target', 'severe_toxicity', 'obscene',\n",
      "       'identity_attack', 'insult', 'threat'],\n",
      "      dtype='object')\n",
      "Done.\n",
      "Perfoming text editing...\n",
      "Done.\n",
      "Transforming text into a sequence of indices...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dataset = DataLoader(path='.\\\\data\\\\train_set.csv', embeddings_path=emb_path, embeddings_size=emb_size, maxlen=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "learning_rate = 5e-4\n",
    "num_classes = 6\n",
    "batch_size = 128 \n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nnPredictor(emb_size, hidden_size, num_layers, num_classes, dataset.emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 3], Step [  6400 / 1399744], Average loss: 0.1135\n",
      "Epoch [1 / 3], Step [ 12800 / 1399744], Average loss: 0.1247\n",
      "Epoch [1 / 3], Step [ 19200 / 1399744], Average loss: 0.1285\n",
      "Epoch [1 / 3], Step [ 25600 / 1399744], Average loss: 0.1305\n",
      "Epoch [1 / 3], Step [ 32000 / 1399744], Average loss: 0.1317\n",
      "Epoch [1 / 3], Step [ 38400 / 1399744], Average loss: 0.1215\n",
      "Epoch [1 / 3], Step [ 44800 / 1399744], Average loss: 0.1297\n",
      "Epoch [1 / 3], Step [ 51200 / 1399744], Average loss: 0.1213\n",
      "Epoch [1 / 3], Step [ 57600 / 1399744], Average loss: 0.1287\n",
      "Epoch [1 / 3], Step [ 64000 / 1399744], Average loss: 0.1287\n",
      "Epoch [1 / 3], Step [ 70400 / 1399744], Average loss: 0.1335\n",
      "Epoch [1 / 3], Step [ 76800 / 1399744], Average loss: 0.1323\n",
      "Epoch [1 / 3], Step [ 83200 / 1399744], Average loss: 0.1370\n",
      "Epoch [1 / 3], Step [ 89600 / 1399744], Average loss: 0.1278\n",
      "Epoch [1 / 3], Step [ 96000 / 1399744], Average loss: 0.1312\n",
      "Epoch [1 / 3], Step [102400 / 1399744], Average loss: 0.1451\n",
      "Epoch [1 / 3], Step [108800 / 1399744], Average loss: 0.1397\n",
      "Epoch [1 / 3], Step [115200 / 1399744], Average loss: 0.1475\n",
      "Epoch [1 / 3], Step [121600 / 1399744], Average loss: 0.1416\n",
      "Epoch [1 / 3], Step [128000 / 1399744], Average loss: 0.1439\n",
      "Epoch [1 / 3], Step [134400 / 1399744], Average loss: 0.1332\n",
      "Epoch [1 / 3], Step [140800 / 1399744], Average loss: 0.1378\n",
      "Epoch [1 / 3], Step [147200 / 1399744], Average loss: 0.1378\n",
      "Epoch [1 / 3], Step [153600 / 1399744], Average loss: 0.1555\n",
      "Epoch [1 / 3], Step [160000 / 1399744], Average loss: 0.1446\n",
      "Epoch [1 / 3], Step [166400 / 1399744], Average loss: 0.1361\n",
      "Epoch [1 / 3], Step [172800 / 1399744], Average loss: 0.1353\n",
      "Epoch [1 / 3], Step [179200 / 1399744], Average loss: 0.1422\n",
      "Epoch [1 / 3], Step [185600 / 1399744], Average loss: 0.1415\n",
      "Epoch [1 / 3], Step [192000 / 1399744], Average loss: 0.1378\n",
      "Epoch [1 / 3], Step [198400 / 1399744], Average loss: 0.1291\n",
      "Epoch [1 / 3], Step [204800 / 1399744], Average loss: 0.1300\n",
      "Epoch [1 / 3], Step [211200 / 1399744], Average loss: 0.1421\n",
      "Epoch [1 / 3], Step [217600 / 1399744], Average loss: 0.1469\n",
      "Epoch [1 / 3], Step [224000 / 1399744], Average loss: 0.1569\n",
      "Epoch [1 / 3], Step [230400 / 1399744], Average loss: 0.1504\n",
      "Epoch [1 / 3], Step [236800 / 1399744], Average loss: 0.1313\n",
      "Epoch [1 / 3], Step [243200 / 1399744], Average loss: 0.1378\n",
      "Epoch [1 / 3], Step [249600 / 1399744], Average loss: 0.1453\n",
      "Epoch [1 / 3], Step [256000 / 1399744], Average loss: 0.1358\n",
      "Epoch [1 / 3], Step [262400 / 1399744], Average loss: 0.1303\n",
      "Epoch [1 / 3], Step [268800 / 1399744], Average loss: 0.1436\n",
      "Epoch [1 / 3], Step [275200 / 1399744], Average loss: 0.1409\n",
      "Epoch [1 / 3], Step [281600 / 1399744], Average loss: 0.1402\n",
      "Epoch [1 / 3], Step [288000 / 1399744], Average loss: 0.1464\n",
      "Epoch [1 / 3], Step [294400 / 1399744], Average loss: 0.1455\n",
      "Epoch [1 / 3], Step [300800 / 1399744], Average loss: 0.1444\n",
      "Epoch [1 / 3], Step [307200 / 1399744], Average loss: 0.1495\n",
      "Epoch [1 / 3], Step [313600 / 1399744], Average loss: 0.1399\n",
      "Epoch [1 / 3], Step [320000 / 1399744], Average loss: 0.1405\n",
      "Epoch [1 / 3], Step [326400 / 1399744], Average loss: 0.1450\n",
      "Epoch [1 / 3], Step [332800 / 1399744], Average loss: 0.1353\n",
      "Epoch [1 / 3], Step [339200 / 1399744], Average loss: 0.1443\n",
      "Epoch [1 / 3], Step [345600 / 1399744], Average loss: 0.1406\n",
      "Epoch [1 / 3], Step [352000 / 1399744], Average loss: 0.1366\n",
      "Epoch [1 / 3], Step [358400 / 1399744], Average loss: 0.1437\n",
      "Epoch [1 / 3], Step [364800 / 1399744], Average loss: 0.1426\n",
      "Epoch [1 / 3], Step [371200 / 1399744], Average loss: 0.1384\n",
      "Epoch [1 / 3], Step [377600 / 1399744], Average loss: 0.1391\n",
      "Epoch [1 / 3], Step [384000 / 1399744], Average loss: 0.1443\n",
      "Epoch [1 / 3], Step [390400 / 1399744], Average loss: 0.1352\n",
      "Epoch [1 / 3], Step [396800 / 1399744], Average loss: 0.1395\n",
      "Epoch [1 / 3], Step [403200 / 1399744], Average loss: 0.1490\n",
      "Epoch [1 / 3], Step [409600 / 1399744], Average loss: 0.1397\n",
      "Epoch [1 / 3], Step [416000 / 1399744], Average loss: 0.1248\n",
      "Epoch [1 / 3], Step [422400 / 1399744], Average loss: 0.1369\n",
      "Epoch [1 / 3], Step [428800 / 1399744], Average loss: 0.1428\n",
      "Epoch [1 / 3], Step [435200 / 1399744], Average loss: 0.1368\n",
      "Epoch [1 / 3], Step [441600 / 1399744], Average loss: 0.1429\n",
      "Epoch [1 / 3], Step [448000 / 1399744], Average loss: 0.1456\n",
      "Epoch [1 / 3], Step [454400 / 1399744], Average loss: 0.1367\n",
      "Epoch [1 / 3], Step [460800 / 1399744], Average loss: 0.1271\n",
      "Epoch [1 / 3], Step [467200 / 1399744], Average loss: 0.1350\n",
      "Epoch [1 / 3], Step [473600 / 1399744], Average loss: 0.1409\n",
      "Epoch [1 / 3], Step [480000 / 1399744], Average loss: 0.1218\n",
      "Epoch [1 / 3], Step [486400 / 1399744], Average loss: 0.1336\n",
      "Epoch [1 / 3], Step [492800 / 1399744], Average loss: 0.1363\n",
      "Epoch [1 / 3], Step [499200 / 1399744], Average loss: 0.1303\n",
      "Epoch [1 / 3], Step [505600 / 1399744], Average loss: 0.1217\n",
      "Epoch [1 / 3], Step [512000 / 1399744], Average loss: 0.1388\n",
      "Epoch [1 / 3], Step [518400 / 1399744], Average loss: 0.1297\n",
      "Epoch [1 / 3], Step [524800 / 1399744], Average loss: 0.1250\n",
      "Epoch [1 / 3], Step [531200 / 1399744], Average loss: 0.1249\n",
      "Epoch [1 / 3], Step [537600 / 1399744], Average loss: 0.1323\n",
      "Epoch [1 / 3], Step [544000 / 1399744], Average loss: 0.1213\n",
      "Epoch [1 / 3], Step [550400 / 1399744], Average loss: 0.1194\n",
      "Epoch [1 / 3], Step [556800 / 1399744], Average loss: 0.1293\n",
      "Epoch [1 / 3], Step [563200 / 1399744], Average loss: 0.1295\n",
      "Epoch [1 / 3], Step [569600 / 1399744], Average loss: 0.1489\n",
      "Epoch [1 / 3], Step [576000 / 1399744], Average loss: 0.1242\n",
      "Epoch [1 / 3], Step [582400 / 1399744], Average loss: 0.1260\n",
      "Epoch [1 / 3], Step [588800 / 1399744], Average loss: 0.1378\n",
      "Epoch [1 / 3], Step [595200 / 1399744], Average loss: 0.1409\n",
      "Epoch [1 / 3], Step [601600 / 1399744], Average loss: 0.1303\n",
      "Epoch [1 / 3], Step [608000 / 1399744], Average loss: 0.1253\n",
      "Epoch [1 / 3], Step [614400 / 1399744], Average loss: 0.1300\n",
      "Epoch [1 / 3], Step [620800 / 1399744], Average loss: 0.1344\n",
      "Epoch [1 / 3], Step [627200 / 1399744], Average loss: 0.1400\n",
      "Epoch [1 / 3], Step [633600 / 1399744], Average loss: 0.1364\n",
      "Epoch [1 / 3], Step [640000 / 1399744], Average loss: 0.1300\n",
      "Epoch [1 / 3], Step [646400 / 1399744], Average loss: 0.1356\n",
      "Epoch [1 / 3], Step [652800 / 1399744], Average loss: 0.1261\n",
      "Epoch [1 / 3], Step [659200 / 1399744], Average loss: 0.1313\n",
      "Epoch [1 / 3], Step [665600 / 1399744], Average loss: 0.1257\n",
      "Epoch [1 / 3], Step [672000 / 1399744], Average loss: 0.1345\n",
      "Epoch [1 / 3], Step [678400 / 1399744], Average loss: 0.1335\n",
      "Epoch [1 / 3], Step [684800 / 1399744], Average loss: 0.1371\n",
      "Epoch [1 / 3], Step [691200 / 1399744], Average loss: 0.1310\n",
      "Epoch [1 / 3], Step [697600 / 1399744], Average loss: 0.1294\n",
      "Epoch [1 / 3], Step [704000 / 1399744], Average loss: 0.1320\n",
      "Epoch [1 / 3], Step [710400 / 1399744], Average loss: 0.1363\n",
      "Epoch [1 / 3], Step [716800 / 1399744], Average loss: 0.1405\n",
      "Epoch [1 / 3], Step [723200 / 1399744], Average loss: 0.1309\n",
      "Epoch [1 / 3], Step [729600 / 1399744], Average loss: 0.1411\n",
      "Epoch [1 / 3], Step [736000 / 1399744], Average loss: 0.1453\n",
      "Epoch [1 / 3], Step [742400 / 1399744], Average loss: 0.1387\n",
      "Epoch [1 / 3], Step [748800 / 1399744], Average loss: 0.1381\n",
      "Epoch [1 / 3], Step [755200 / 1399744], Average loss: 0.1304\n",
      "Epoch [1 / 3], Step [761600 / 1399744], Average loss: 0.1349\n",
      "Epoch [1 / 3], Step [768000 / 1399744], Average loss: 0.1234\n",
      "Epoch [1 / 3], Step [774400 / 1399744], Average loss: 0.1429\n",
      "Epoch [1 / 3], Step [780800 / 1399744], Average loss: 0.1388\n",
      "Epoch [1 / 3], Step [787200 / 1399744], Average loss: 0.1414\n",
      "Epoch [1 / 3], Step [793600 / 1399744], Average loss: 0.1372\n",
      "Epoch [1 / 3], Step [800000 / 1399744], Average loss: 0.1352\n",
      "Epoch [1 / 3], Step [806400 / 1399744], Average loss: 0.1388\n",
      "Epoch [1 / 3], Step [812800 / 1399744], Average loss: 0.1357\n",
      "Epoch [1 / 3], Step [819200 / 1399744], Average loss: 0.1337\n",
      "Epoch [1 / 3], Step [825600 / 1399744], Average loss: 0.1450\n",
      "Epoch [1 / 3], Step [832000 / 1399744], Average loss: 0.1400\n",
      "Epoch [1 / 3], Step [838400 / 1399744], Average loss: 0.1210\n",
      "Epoch [1 / 3], Step [844800 / 1399744], Average loss: 0.1259\n",
      "Epoch [1 / 3], Step [851200 / 1399744], Average loss: 0.1389\n",
      "Epoch [1 / 3], Step [857600 / 1399744], Average loss: 0.1391\n",
      "Epoch [1 / 3], Step [864000 / 1399744], Average loss: 0.1291\n",
      "Epoch [1 / 3], Step [870400 / 1399744], Average loss: 0.1401\n",
      "Epoch [1 / 3], Step [876800 / 1399744], Average loss: 0.1361\n",
      "Epoch [1 / 3], Step [883200 / 1399744], Average loss: 0.1486\n",
      "Epoch [1 / 3], Step [889600 / 1399744], Average loss: 0.1371\n",
      "Epoch [1 / 3], Step [896000 / 1399744], Average loss: 0.1484\n",
      "Epoch [1 / 3], Step [902400 / 1399744], Average loss: 0.1479\n",
      "Epoch [1 / 3], Step [908800 / 1399744], Average loss: 0.1466\n",
      "Epoch [1 / 3], Step [915200 / 1399744], Average loss: 0.1465\n",
      "Epoch [1 / 3], Step [921600 / 1399744], Average loss: 0.1413\n",
      "Epoch [1 / 3], Step [928000 / 1399744], Average loss: 0.1353\n",
      "Epoch [1 / 3], Step [934400 / 1399744], Average loss: 0.1371\n",
      "Epoch [1 / 3], Step [940800 / 1399744], Average loss: 0.1239\n",
      "Epoch [1 / 3], Step [947200 / 1399744], Average loss: 0.1303\n",
      "Epoch [1 / 3], Step [953600 / 1399744], Average loss: 0.1324\n",
      "Epoch [1 / 3], Step [960000 / 1399744], Average loss: 0.1229\n",
      "Epoch [1 / 3], Step [966400 / 1399744], Average loss: 0.1330\n",
      "Epoch [1 / 3], Step [972800 / 1399744], Average loss: 0.1356\n",
      "Epoch [1 / 3], Step [979200 / 1399744], Average loss: 0.1287\n",
      "Epoch [1 / 3], Step [985600 / 1399744], Average loss: 0.1384\n",
      "Epoch [1 / 3], Step [992000 / 1399744], Average loss: 0.1424\n",
      "Epoch [1 / 3], Step [998400 / 1399744], Average loss: 0.1341\n",
      "Epoch [1 / 3], Step [1004800 / 1399744], Average loss: 0.1402\n",
      "Epoch [1 / 3], Step [1011200 / 1399744], Average loss: 0.1333\n",
      "Epoch [1 / 3], Step [1017600 / 1399744], Average loss: 0.1347\n",
      "Epoch [1 / 3], Step [1024000 / 1399744], Average loss: 0.1349\n",
      "Epoch [1 / 3], Step [1030400 / 1399744], Average loss: 0.1254\n",
      "Epoch [1 / 3], Step [1036800 / 1399744], Average loss: 0.1462\n",
      "Epoch [1 / 3], Step [1043200 / 1399744], Average loss: 0.1416\n",
      "Epoch [1 / 3], Step [1049600 / 1399744], Average loss: 0.1575\n",
      "Epoch [1 / 3], Step [1056000 / 1399744], Average loss: 0.1544\n",
      "Epoch [1 / 3], Step [1062400 / 1399744], Average loss: 0.1554\n",
      "Epoch [1 / 3], Step [1068800 / 1399744], Average loss: 0.1546\n",
      "Epoch [1 / 3], Step [1075200 / 1399744], Average loss: 0.1509\n",
      "Epoch [1 / 3], Step [1081600 / 1399744], Average loss: 0.1442\n",
      "Epoch [1 / 3], Step [1088000 / 1399744], Average loss: 0.1521\n"
     ]
    }
   ],
   "source": [
    "model.train(dataset, num_epochs, verbose_step=batch_size * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
