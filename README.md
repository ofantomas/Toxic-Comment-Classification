# Toxic-Comment-Classification
See https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification for details on challenge and for data.

This repo contains a Jupyter Notebook with all the experiments as well as a script, which performs toxic comment classification, using an ensemble of models, trained on different embeddings. readme.txt contains instructions on how to use the script.

Embeddings and data for training and for testing are not included in repo.
